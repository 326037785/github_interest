Depth Prediction Without the Sensors: Leveraging Structure for Unsupervised Learning from Monocular Videos
https://github.com/tensorflow/models/tree/master/research/struct2depth

DeepTAM: Deep Tracking and Mapping
https://github.com/lmb-freiburg/deeptam

FADNet: A Fast and Accurate Network for Disparity Estimation
https://github.com/HKBU-HPML/FADNet

code for Mesh R-CNN, an academic publication, presented at ICCV 2019
https://github.com/facebookresearch/meshrcnn

单目图像深度估计的Tensorflow C++实现
https://github.com/yan99033/monodepth-cpp

【用卷积网络将2D照片转换成3D】《Powered by AI: Turning any 2D photo into 3D using convolutional neural nets》
https://ai.facebook.com/blog/powered-by-ai-turning-any-2d-photo-into-3d-using-convolutional-neural-nets/

A Pytorch implementation of Pyramid Stereo Matching Network
https://github.com/KinglittleQ/PSMNet

A PyTorch Library for Accelerating 3D Deep Learning Research
https://github.com/NVIDIAGameWorks/kaolin

A pytorch implementation of "D4LCN: Learning Depth-Guided Convolutions for Monocular 3D Object Detection"
https://github.com/dingmyu/D4LCN

it referenced paper of GANerated Hands for Real-Time 3D Hand Tracking from Monocular RGB.
https://github.com/Ninebell/GaneratedHandsForReal_TIME

Hierarchical Deep Stereo Matching on High Resolution Images, CVPR 2019. 
https://github.com/gengshan-y/high-res-stereo

【PIFu：单图片3D着装人体数字化】《PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization》 
https://github.com/shunsukesaito/PIFu

Learning View Priors for Single-view 3D Reconstruction
https://github.com/hiroharu-kato/view_prior_learning

The official implementation of the ICCV 2019 paper "GraphX-convolution for point cloud deformation in 2D-to-3D conversion".
https://github.com/justanhduc/graphx-conv

Official pytorch implementation of "Indoor Depth Completion with Boundary Consistency and Self-Attention. Huang et al. RLQ@ICCV 2019." https://arxiv.org/abs/1908.08344
https://github.com/patrickwu2/Depth-Completion

MVSNet: Depth Inference for Unstructured Multi-view Stereo. 
https://github.com/xy-guo/MVSNet_pytorch

Neural network code for Deep Blending for Free-Viewpoint Image-Based Rendering (SIGGRAPH Asia 2018)
https://github.com/Phog/DeepBlending

Extreme View Synthesis
https://github.com/NVlabs/extreme-view-synth

Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer (NeurIPS 2019)
https://github.com/nv-tlabs/DIB-R

CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction
https://github.com/yan99033/CNN-SVO

TriDepth: Triangular Patch-based Deep Depth Prediction [Kaneko+, ICCVW2019(oral)]
https://github.com/syinari0123/tridepth

From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation
https://github.com/cogaplex-bts/bts

Geometry meets semantics for semi-supervised monocular depth estimation - ACCV 2018
https://github.com/CVLAB-Unibo/Semantic-Mono-Depth

PyTorch implementation for LayoutNet v2 in the paper: "3D Manhattan Room Layout Reconstruction from a Single 360 Image"
https://github.com/zouchuhang/LayoutNetv2

Real-Time 3D Semantic Reconstruction from 2D data
https://github.com/MIT-SPARK/Kimera-Semantics

This repo includes the source code of the fully convolutional depth denoising model presented in https://arxiv.org/pdf/1909.01193.pdf
https://github.com/VCL3D/DeepDepthDenoising

This is the project page of the paper "Flow-Motion and Depth Network for Monocular Stereo and Beyond''
https://github.com/HKUST-Aerial-Robotics/Flow-Motion-Depth

【神经网络3D重建资源列表】
https://github.com/natowi/3D-Reconstruction-with-Neural-Network

Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video (NeurIPS 2019)
https://github.com/JiawangBian/SC-SfMLearner-Release

深度学习深度估计研究指南
https://pan.baidu.com/s/1RhORsmInOk1ZEmOKuUeybw

《Do As I Do: Transferring Human Motion and Appearance between Monocular Videos with Spatial and Temporal Constraints》
https://www.arxiv-vanity.com/papers/2001.02606/

(PyTorch)合成-现实(Synthetic-to-Realistic)转换深度估计
https://github.com/lyndonzheng/Synthetic2Realistic

用强化学习装宜家家具——IKEA(宜家)家具组装仿真环境，用于促进长期操作任务的解决：80多个家具模型、多个机器人、多观察角度、支持 OpenAI gym 
https://github.com/clvrai/furniture

三维深度学习论文列表
https://github.com/pointcloudlearning/3D-Deep-Learning-Paper-List

【整体3D重建论文/资源列表】'Holistic 3D Reconstruction - A list of papers and resources for holistic 3D reconstruction' 
https://github.com/holistic-3d/awesome-holistic-3d

'Facebook360 Depth Estimation Pipeline (facebook360_dep) - a computational imaging software pipeline supporting on-line marker-less calibration, high-quality reconstruction, and real-time streaming and rendering of 6DoF content.' 
https://github.com/facebook/facebook360_dep

ICCV的3D Vision Tutorial
https://holistic-3d.github.io/iccv19/ 其实计算机视觉一开始就是研究3D重建问题的。当时几乎所有的奠基者都一致地在研究如何从二维的点、线、面恢复三维结构。用这些几何元素的理由来自于人的perception和cognition。所以一开始计算机视觉就是把recognition和reconstruction统一在三维重建这个问题中的。只是后来，做三维的开始淡化recognition，认为用局部features就够了，所以目前几乎所有三维重建系统（SfM，vSLAM）都是非常不稳定不鲁棒；而做recognition的开始淡化3D，集中在2D图像上做识别，然后认为三维可以从数据学来，不需要几何。这一分就是近二十年。而现在两边的都发现需要对方，不然计算机视觉真正落地就是做梦。

PyTorch无监督单目深度估计
https://github.com/ClubAI/MonoDepth-PyTorch

A collection of segmentation methods working on depth images
https://github.com/ethz-asl/depth_segmentation

正交特征变换单目三维目标检测
https://github.com/tom-roddick/oft

Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image
https://github.com/mks0601/3DMPPE_ROOTNET_RELEASE

SharpNet: Fast and Accurate Recovery of Occluding Contours in Monocular Depth Estimation
https://github.com/MichaelRamamonjisoa/SharpNet

What Do Single-view 3D Reconstruction Networks Learn?
https://github.com/lmb-freiburg/what3d

UprightNet: Geometry-Aware Camera Orientation Estimation from Single Images
https://arxiv.org/abs/1908.07070

A customized implementation of the paper "StereoNet: guided hierarchical refinement for real-time edge-aware depth prediction"
https://github.com/zhixuanli/StereoNet

### Tensorflow implementation of Semi-Supervised Monocular Depth Estimation with Left-Right Consistency Using Deep Neural Network.
https://github.com/a-jahani/semiDepth

### Code for the CVPR 2019 paper "Learning Single-Image Depth from Videos using Quality Assessment Networks"
https://github.com/princeton-vl/YouTube3D

A Pytorch implement of 《Deeper Depth Prediction with Fully Convolutional Residual Networks》
https://github.com/XPFly1989/FCRN

Single Image Depth Estimation Trained via Depth from Defocus Cues
https://github.com/shirgur/UnsupervisedDepthFromFocus

SceneGraphNet: Neural Message Passing for 3D Indoor Scene Augmentation
https://github.com/yzhou359/3DIndoor-SceneGraphNet

MultiDepth: Single-Image Depth Estimation via Multi-Task Regression and Classification
https://github.com/lukasliebel/MultiDepth https://arxiv.org/abs/1907.11111

Neural RGB→D Sensing: Per-pixel depth and its uncertainty estimation from a monocular RGB video
https://github.com/NVlabs/neuralrgbd

深度估计相关文献列表
https://github.com/scott89/awesome-depth

Tensorflow implementation of DeepV2D: Video to Depth with Differentiable Structure from Motion.
https://github.com/princeton-vl/DeepV2D

How do neural networks see depth in single images?
https://arxiv.org/abs/1905.07005

基于深度图的2D图像3D化效果
https://github.com/ialhashim/DenseDepth/

CVPR 2019 Translate-to-Recognize Networks for RGB-D Scene Recognition
https://github.com/ownstyledu/Translate-to-Recognize-Networks

DORN: Deep Ordinal Regression Network for Monocular Depth Estimation
https://github.com/hufu6371/DORN

移动像机，移动人物：深度学习深度预测方法
https://arxiv.org/abs/1904.11111
https://ai.googleblog.com/2019/05/moving-camera-moving-people-deep.html

Code for "PackNet-SfM: 3D Packing for Self-Supervised Monocular Depth Estimation"
https://github.com/ToyotaResearchInstitute/packnet-sfm

从平行2D部分进行3D重建的C++工具
https://github.com/paulknysh/shaper

Transformable Bottleneck Networks
https://github.com/kyleolsz/TB-Networks

Recovering 3D Planes from a Single Image via Convolutional Neural Networks
https://github.com/fuy34/planerecover

Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation, CVPR 2019
https://github.com/sshan-zhao/GASDA

Direct Sparse Odometry with CNN Depth Prediction
https://github.com/muskie82/CNN-DSO

Annotation webapp (javascript) used in the research project Scan2CAD: Learning CAD Model Alignment in RGB-D Scans https://www.scan2cad.org
https://github.com/skanti/Scan2CAD-Annotation-Webapp
https://github.com/skanti/Scan2CAD

### Monocular depth estimation from a single image
https://github.com/nianticlabs/monodepth2

### ICRA 2019 "FastDepth: Fast Monocular Depth Estimation on Embedded Systems"
https://github.com/dwofk/fast-depth

### Torch implementation for CVPR 18 paper: "LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image"
https://github.com/zouchuhang/LayoutNet

Stereo R-CNN based 3D Object Detection for Autonomous Driving
https://github.com/HKUST-Aerial-Robotics/Stereo-RCNN

基于Feature Pyramid Network的单图深度估计
https://github.com/xanderchf/MonoDepth-FPN-PyTorch

视频时序一致性学习
https://github.com/phoenix104104/fast_blind_video_consistency
https://arxiv.org/abs/1808.00449​

Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image
https://github.com/fangchangma/sparse-to-dense.pytorch

快速场景理解(分割/实例分割/单图像深度估计)
https://github.com/DavyNeven/fastSceneUnderstanding
torch7 lua
景深图像质量增强资源列表
https://github.com/mdcnn/Depth-Image-Quality-Enhancement

Code for RenderNet: A deep convolutional network for differentiable rendering from 3D shapes
https://github.com/thunguyenphuoc/RenderNet

LabelFusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes http://labelfusion.csail.mit.edu
https://github.com/RobotLocomotion/LabelFusion

[ECCV'18] 3DMV: Joint 3D-Multi-View Prediction for 3D Semantic Scene Segmentation
https://github.com/angeladai/3DMV
https://arxiv.org/abs/1803.10409

Code Repo for "Single View Stereo Matching" 
https://github.com/lawy623/SVS

DeepMVS: Learning Multi-View Stereopsis
https://github.com/phuang17/DeepMVS

Layer-structured 3D Scene Inference via View Synthesis
https://github.com/google/layered-scene-inference

Deep Depth Completion of a Single RGB-D Image
https://github.com/yindaz/DeepCompletionRelease

场景理解和建模挑战(360° RGB-D 3D室内全景理解
https://github.com/facebookresearch/sumo-challenge

Implementation of ICRA 2019 paper: Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation
https://github.com/hlzz/DeepMatchVO

Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding
https://github.com/svip-lab/PlanarReconstruction

High Quality Monocular Depth Estimation via Transfer Learning https://arxiv.org/abs/1812.11941
https://github.com/ialhashim/DenseDepth

# paper
Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
https://arxiv.org/abs/1809.04766

[ECCV 2018] DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency
https://github.com/vt-vl-lab/DF-Net

Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving
https://github.com/mileyan/pseudo_lidar

Neural RGB->D Sensing: Depth and Uncertainty from a Video Camera
https://arxiv.org/abs/1901.02571

### This repository provides official models from the paper Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
https://github.com/DrSleep/multi-task-refinenet

PyTorch implementation of Deep Ordinal Regression Network for Monocular Depth Estimation
https://github.com/dontLoveBugs/DORN_pytorch

The release code and dataset of CNN-MonoFusion for ismar2018
https://github.com/NetEaseAI-CVLab/CNN-MonoFusion
