CNN音频分割(音乐/人声/性别)工具集
https://github.com/ina-foss/inaSpeechSegmenter

最强CNN语音识别算法开源了：词错率5%，训练超快，Facebook出品
https://github.com/facebookresearch/wav2letter

轻量语音识别解码框架
https://github.com/robin1001/xdecoder

Espresso：快速端到端神经网络语音识别工具集
https://github.com/freewym/espresso

PyTorch音频处理工具/数据集
https://github.com/audeering/audtorch

AI音源分离：Facebook AI的Demucs项目帮机器像人一样听音乐
https://github.com/facebookresearch/demucs

Youka：基于spleeter音源分离的卡拉OK生成工具
https://github.com/youkaclub/youka-desktop

基于卷积网络的基音检测
https://0xfe.blogspot.com/2020/02/pitch-detection-with-convolutional.html?m=1

Implementation of "FastSpeech: Fast, Robust and Controllable Text to Speech"
https://github.com/Deepest-Project/FastSpeech

'基于Kaldi的aidatatang_200zh的训练之葵花宝典' 
https://github.com/datatang-ailab/aidatatang_200zh/blob/master/README.zh.md

### 【轻量快速语音合成】’LightSpeech - A Light, Fast and Robust Speech Synthesis.' 
https://github.com/xcmyz/lightspeech

DeepSpectrum：基于预训练图像CNN的音频数据特征抽取工具包
https://github.com/DeepSpectrum/DeepSpectrum

Landmark音频指纹
https://github.com/dpwe/audfprint

基于Kaldi/Tensorflow的神经网络说话人识别/鉴别系统
https://github.com/mycrazycracy/tf-kaldi-speaker

【PyTorch语音识别框架】’patter - speech-to-text framework in PyTorch with initial support for the DeepSpeech2 architecture 
https://github.com/ryanleary/patter

(语音)说话人分割相关资源大列表
https://github.com/wq2012/awesome-diarization

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/SpeechResearch/speechresearch.github.io

(PyTorch)Seq2Seq普通话Transformer语音识别
https://github.com/ZhengkunTian/Speech-Tranformer-Pytorch

Deep neural network based speech enhancement toolkit
https://github.com/jtkim-kaist/Speech-enhancement

音乐音频标记预训练深度网络模型
https://github.com/jordipons/musiCNN

End-to-End Automatic Speech Recognition on PyTorch
https://github.com/gentaiscool/end2end-asr-pytorch

(Pytorch)音源分离语音信号提取
https://github.com/AppleHolic/source_separation

Code and models for evaluating a state-of-the-art lip reading network
https://github.com/afourast/deep_lip_reading

### 声音模仿秀：5秒钟实时克隆任意语音
https://github.com/CorentinJ/Real-Time-Voice-Cloning

Program to benchmark various speech recognition APIs
https://github.com/Franck-Dernoncourt/ASR_benchmark

基于Transformer的TTS语音合成模型
https://github.com/xcmyz/Transformer-TTS

DIY智能音箱(资源列表)
https://github.com/voice-engine/make-a-smart-speaker/blob/master/zh.md

用深度学习实时克隆别人的声音
https://towardsdatascience.com/you-can-now-speak-using-someone-elses-voice-with-deep-learning-8be24368fa2b

用卷积网络从立体声音乐中分离乐器
https://towardsdatascience.com/audio-ai-isolating-instruments-from-stereo-music-using-convolutional-neural-networks-584ababf69de

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

面向下一代交互设备的开源语音交互操作系统
https://github.com/yodaos-project/yodaos

笑声检测器
https://github.com/ideo/LaughDetection

'ASRT_SpeechRecognition - A Deep-Learning-Based Chinese Speech Recognition System 基于深度学习的中文语音识别系统' by nl8590687
https://github.com/nl8590687/ASRT_SpeechRecognition

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

A Pytorch Implementation of "Neural Speech Synthesis with Transformer Network"
https://github.com/soobinseo/Transformer-TTS

This is research-code for Synthesizing Obama: Learning Lip Sync from Audio.
https://github.com/supasorn/synthesizing_obama_network_training

Voice Operated Character Animation https://voca.is.tue.mpg.de/en
https://github.com/TimoBolkart/voca

Deezer 的(Tensorflow)音源分离库，可用命令行直接提取音乐中的人声、钢琴、鼓声等
https://github.com/deezer/spleeter

【开源语音分离/增强库】
https://github.com/speechLabBcCuny/onssen

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG

Transforming Spectrum and Prosody for Emotional Voice Conversion with Non-Parallel Training Data
https://github.com/KunZhou9646/Nonparallel-emotional-VC

This is a PyTorch re-implementation of Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition.
https://github.com/foamliu/Speech-Transformer

【Athena：开源端到端语音识别引擎】
https://github.com/athena-team/athena

PREDICTING EXPRESSIVE SPEAKING STYLE FROM TEXT IN END-TO-END SPEECH SYNTHESIS
https://github.com/Yangyangii/TPGST-Tacotron

PyTorch implementation of LF-MMI for End-to-end ASR
https://github.com/YiwenShaoStephen/pychain

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/RayeRen/unsuper_tts_asr

 Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.
 https://github.com/CSTR-Edinburgh/ophelia

Efficient neural speech synthesis
https://github.com/MlWoo/LPCNet

Code for Vision-Infused Deep Audio Inpainting (ICCV 2019)
https://github.com/Hangz-nju-cuhk/Vision-Infused-Audio-Inpainter-VIAI

deep learning based speech enhancement using keras or pytorch
https://github.com/yongxuUSTC/sednn

Multi-voice singing voice synthesis
https://github.com/MTG/WGANSing

【用涂鸦“唱歌”：将图像合成为声音】
https://github.com/jeonghopark/SketchSynth-Simple

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG


【面向语音识别的中文/英文发音辞典】’
https://github.com/speech-io/BigCiDian

### 【Kaldi/TensorFlow实现的神经网络说话人验证系统】
https://github.com/someonefighting/tf-kaldi-speaker-master

### Facebook开源低延迟在线语音识别框架wav2letter
https://github.com/facebookresearch/wav2letter/wiki/Inference-Framework

【GridSound：在线数字音频编辑器】
https://github.com/GridSound/daw

【Asteroid：基于PyTorch的音源分离工具集】
https://github.com/mpariente/ASSteroid

【MelGAN 超快音频合成】
https://github.com/descriptinc/melgan-neurips

用深度学习生成钢琴音乐
https://github.com/haryoa/note_music_generator

音频分析/音乐检索相关数据集大列表
https://www.audiocontentanalysis.org/data-sets/

### 【用TensorRT在GPU上部署实时文本-语音合成应用】
https://devblogs.nvidia.com/how-to-deploy-real-time-text-to-speech-applications-on-gpus-using-tensorrt/

用WaveNet让语音受损用户重拾原声(少样本自适应自然语音合成)
https://deepmind.com/blog/article/Using-WaveNet-technology-to-reunite-speech-impaired-users-with-their-original-voices

(C++)音频文件波形图生成
https://github.com/bbc/audiowaveform

【时域卷积DeepFake变音检测】
https://github.com/dessa-public/fake-voice-detection

Athena：(Tensorflow)端到端自动语音识别引擎开源实现
https://github.com/didi/athena

SV2TTS 
https://github.com/CorentinJ/Real-Time-Voice-Cloning

### 【GPU上的特定领域自动语音识别模型】《How to Build Domain Specific Automatic Speech Recognition Models on GPUs》
https://devblogs.nvidia.com/how-to-build-domain-specific-automatic-speech-recognition-models-on-gpus/

【(音频)数字信号处理入门(Notebooks)】
https://github.com/earthspecies/from_zero_to_DSP

### 【at16k：Python语音识别库】’at16k - Trained models for automatic speech recognition (ASR). A library to quickly build applications that require speech to text conversion.'
https://github.com/at16k/at16k

一维卷积网络音频处理
https://github.com/KinWaiCheuk/nnAudio

CRF数据高效端到端语音识别工具集
https://github.com/thu-spmi/CAT

【音乐波形域音源分离】’Music Source Separation in the Waveform Domain - source separation in the waveform domain for music' 
https://github.com/facebookresearch/demucs

【Python实时音频频谱分析器】’Realtime_PyAudio_FFT - Realtime audio analysis in Python, using PyAudio and Numpy to extract and visualize FFT features from streaming audio.' 
https://github.com/tr1pzz/Realtime_PyAudio_FFT

Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis
https://github.com/NVIDIA/flowtron 

【文本语音合成(TTS)文献集】
https://github.com/erogol/TTS-papers

【CPU高性能实时文本语音合成系统】
https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/

【TensorFlow 2 实现的文本语音合成】
https://github.com/as-ideas/TransformerTTS

【语音增强/语音分离/音源分离相关资源大列表】
https://github.com/Wenzhe-Liu/awesome-speech-enhancement

【AudioMass：全功能网页版音频/波形编辑工具
https://github.com/pkalogiros/AudioMass

【CTC端到端语音识别&语料库】’CTC-based Automatic Speech Recogniton - CTC end -to-end ASR for timit and 863 corpus.' 
https://github.com/Diamondfan/CTC_pytorch

【TensorflowTTS：Tensorflow 2实现的最先进实时语音合成】
https://github.com/dathudeptrai/TensorflowTTS

【audio：面向语音行为检测、二值化、说话人识别、自动语音识别、情感识别等任务的音频标注工具】
https://github.com/midas-research/audino

【深度学习语音端点检测】
https://github.com/filippogiruzzi/voice_activity_detection

【用Kaldi快速训练语音识别系统】
https://github.com/JRMeyer/easy-kaldi

从一首歌的mp3中分离得到人声、谱子、各种乐器等，转化成符号表示
https://github.com/deezer/spleeter

'aukit - 语音处理工具箱，包含语音降噪、音频格式转换、特征频谱生成等模块'
https://github.com/KuangDD/aukit

【Keras示例：说话人识别】《Speaker Recognition》
https://keras.io/examples/audio/speaker_recognition_using_cnn/

基于RNN-Transducer的在线语音识别系统
https://github.com/theblackcat102/Online-Speech-Recognition

### 'TacotronV2 + WaveRNN - tacotronV2 + wavernn 实现中文语音合成(Tensorflow + pytorch)'
https://github.com/lturing/tacotronv2_wavernn_chinese

【miniaudio：C语言单文件音频回放/采集库】
https://github.com/dr-soft/miniaudio https://github.com/irmen/pyminiaudio

【TiramisuASR：用Tensorflow 2实现的语音识别引擎】
https://github.com/usimarit/TiramisuASR

A PyTorch implementation of dual-path RNNs (DPRNNs) based speech separation described in "Dual-path RNN: efficient long sequence modeling for time-domain single-channel speech separation".
https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation

Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural Speaker Embeddings
https://github.com/nii-yamagishilab/multi-speaker-tacotron

Code repo for ICME 2020 paper "Style-Conditioned Music Generation". VAE model that allows style-conditioned music generation.
https://github.com/daQuincy/DeepMusicvStyle

streaming attention networks for end-to-end automatic speech recognition
https://github.com/HaoranMiao/streaming-attention

[InterSpeech 2020] "AutoSpeech: Neural Architecture Search for Speaker Recognition" 
https://github.com/TAMU-VITA/AutoSpeech

Pytorch implementation of sparse_image_warp and an example of GoogleBrain's SpecAugment is given: A Simple Data Augmentation Method for Automatic Speech Recognition
https://github.com/bobchennan/sparse_image_warp_pytorch

A Generative Flow for Text-to-Speech via Monotonic Alignment Search
https://github.com/jaywalnut310/glow-tts

DeCoAR (self-supervised contextual representations for speech recognition)
https://github.com/awslabs/speech-representations

A pytorch implementation of the EATS: End-to-End Adversarial Text-to-Speech
https://github.com/yanggeng1995/EATS

Companion repository for the paper "A Comparison of Metric Learning Loss Functions for End-to-End Speaker Verification"
https://github.com/juanmc2005/SpeakerEmbeddingLossComparison

Melody extraction using joint detection and classification network
https://github.com/keums/melodyExtraction_JDC

Implementation of the AlignTTS
https://github.com/Deepest-Project/AlignTTS

An implementation of Microsoft's "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"
https://github.com/ming024/FastSpeech2

It's an naive implementation of Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech.
https://github.com/AppleHolic/multiband_melgan

PyTorch Implementation of FastSpeech 2 : Fast and High-Quality End-to-End Text to Speech
https://github.com/rishikksh20/FastSpeech2

GELP: GAN-Excited Linear Prediction
https://github.com/ljuvela/GELP

### CASR-DEMO(中文自动语音识别演示系统） - 基于Flask Web的中文自动语音识别演示系统,包含语音识别、语音合成、声纹识别之说话人识别
https://github.com/lihanghang/CASR-DEMO

Unofficial PyTorch implementation of Multi-Band MelGAN paper
https://github.com/rishikksh20/melgan

### 中文语音识别 - Chinese speech recognition
https://github.com/chenmingxiang110/Chinese-automatic-speech-recognition

### MASR 中文语音识别：端到端深度神经网络中文普通话语音识别项目
https://github.com/nobody132/masr

Plover：开源跨平台速记引擎，每分钟可录入200+单词
http://www.openstenoproject.org/plover/

【“Python机器学习声源分离”源码】
https://github.com/masahitotogami/python_source_separation

【可移植的C语言声学指纹库】
https://github.com/JorenSix/Olaf

SpeedySpeech：师生网络高质量实时语音合成系统
https://github.com/janvainer/speedyspeech

音频/语音预训练模型集
https://github.com/balavenkatesh3322/audio-pretrained-model

Piano transcription：钢琴曲MIDI文件转写工具
https://arxiv.org/abs/2010.01815 https://github.com/bytedance/piano_transcription

CorentinJ/Real-Time-Voice-Cloning 
https://github.com/KuangDD/zhrtvc

工业级语音识别文献集(Streaming ASR / Non-autoregressive ASR / WFST based ASR ...)
https://github.com/xingchensong/speech-recognition-papers

pyttsx3：Python离线语音合成库
https://github.com/nateshmbhat/pyttsx3

TensorflowASR：Tensorflow2实现的最先进语音识别
https://github.com/Z-yq/TensorflowASR

Cornell鸟鸣识别比赛第二名方案
https://github.com/vlomme/Birdcall-Identification-competition

micmon：从原始音频流分割创建音频数据集并训练声音检测模型的Python库
https://github.com/BlackLight/micmon

### LibreASR：开箱即用的流语音识别系统(基于PyTorch&fastai )
https://github.com/iceychris/LibreASR

Voicenet：语音和音频的综合Python处理库
https://github.com/Robofied/Voicenet

musicpy：音乐编程语言，用简洁的语法通过乐理逻辑写出优美音乐
https://github.com/Rainbow-Dreamer/musicpy

SOVA ASR：基于Wav2Letter架构的快速语音识别API
https://github.com/sovaai/sova-asr

### ZhTTS：CPU上的开源端到端实时中文语音合成系统
https://github.com/Jackiexiao/zhtts

SeeWav: 音频波形可视化包
https://github.com/adefossez/seewav

神经网络语音分离必读文献列表
https://github.com/JusperLee/Speech-Separation-Paper-Tutorial

PIKA: 基于Pytorch和(Py)Kaldi的轻量语音处理工具包
https://github.com/tencent-ailab/pika

### ESP-Skainet：智能语音助手，支持唤醒词识别和命令词识别
https://github.com/espressif/esp-skainet

### TensorFlow Lite (TFLite)的TTS模型集
https://github.com/tulasiram58827/TTS_TFLite

Elpis (Accelerated Transcription)：开发中的语音识别模型创建工具
https://github.com/CoEDL/elpis

MusicNet：带标注的古典音乐数据集(330+)，标注了每个音符的精确时间，演奏每个音符的乐器，以及这些音符在乐曲韵律结构中的位置
https://homes.cs.washington.edu/~thickstn/musicnet.html

AI音乐生成
https://alxmamaev.medium.com/generating-music-with-ai-or-transformers-go-brrrr-3a3ac5a04126

Real Time Speech Enhancement in the Waveform Domain (Interspeech 2020)We provide a PyTorch implementation of the paper Real Time Speech Enhancement in the Waveform Domain.
https://github.com/facebookresearch/denoiser

Implementation of MelNet in PyTorch to generate high-fidelity audio samples
https://github.com/jgarciapueyo/MelNet-SpeechGeneration

PPSpeech: Phrase based Parallel End-to-End TTS System
https://github.com/rishikksh20/PPSpeech

Implementation of Phase-aware speech enhancement with deep complex U-Net
https://github.com/mhlevgen/DCUNetTorchSound

Tensorflow 2.0 implementation of the paper: A Fully Convolutional Neural Network for Speech Enhancement
https://github.com/daitan-innovation/cnn-audio-denoiser

### Voice Conversion by CycleGAN (语音克隆/语音转换): CycleGAN-VC2
https://github.com/jackaduma/CycleGAN-VC2

HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
https://github.com/jik876/hifi-gan

Real-Time High-Fidelity Speech Synthesis without GPU
https://github.com/BogiHsu/WG-WaveNet

Official PyTorch implementation of Speaker Conditional WaveRNN
https://github.com/dipjyoti92/SC-WaveRNN

Pytorch implementation of "Efficienttts: an efficient and high-quality text-to-speech architecture"
https://github.com/liusongxiang/efficient_tts

HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
https://github.com/rishikksh20/HiFi-GAN

An unofficial implementation of the paper "One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization".
https://github.com/cyhuang-tw/AdaIN-VC

TFGAN: Time and Frequency Domain Based Generative Adversarial Network for High-fidelity Speech Synthesis
https://github.com/rishikksh20/TFGAN

Efficient neural networks for analog audio effect modeling
https://github.com/csteinmetz1/micro-tcn

End-to-End Multi-Channel Transformer for Speech Recognition
https://arxiv.org/abs/2102.03951

Hugging Face的Transformers v4.3.0最新发布，hub模型库增加Facebook的Wav2Vec2自动语音识别模型
https://huggingface.co/facebook/wav2vec2-base-960h

LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search
https://arxiv.org/abs/2102.04040

End-to-end Audio-visual Speech Recognition with Conformers
https://arxiv.org/abs/2102.06657

### TTS_TFLite
https://github.com/tulasiram58827/TTS_TFLite

Memory-efficient Speech Recognition on Smart Devices
https://arxiv.org/abs/2102.11531

自监督学习语音识别，wav2vec 2.0框架封装版
https://github.com/mailong25/self-supervised-speech-recognition

音频自动描述相关资源列表
https://github.com/audio-captioning/audio-captioning-resources

### PyTorch implementation of "Conformer: Convolution-augmented Transformer for Speech Recognition" (INTERSPEECH 2020)
https://github.com/sooftware/conformer

OpenASR：基于Pytorch的端到端语音识别系统 
https://github.com/by2101/OpenASR

实时音频频谱生成(网页版)
https://borismus.github.io/spectrogram/

【WavEncoder：PyTorch后端的原始音频编码库】
https://github.com/shangeth/wavencoder

【Picovoice：用于大规模语音产品构建的端到端平台】
github.com/Picovoice/picovoice 

audlib：以深度学习为重点的Python语音信号处理库
https://github.com/raymondxyy/pyaudlib

Auto-Editor：命令行视频/音频自动编辑工具，自动切除静默部分
https://github.com/WyattBlue/auto-editor

The SpeechBrain Toolkit：PyTorch开源一体化语音工具包，可用来轻松开发最先进的语音系统，包括语音识别、讲话者识别、语音增强、多麦克风信号处理等
github.com/speechbrain/speechbrain

STT：用于训练和部署语音到文本模型的开源深度学习工具包
github.com/coqui-ai/STT

GigaSpeech：用于语音识别的大型现代数据集
 github.com/SpeechColab/GigaSpeech