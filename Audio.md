CNN音频分割(音乐/人声/性别)工具集
https://github.com/ina-foss/inaSpeechSegmenter

最强CNN语音识别算法开源了：词错率5%，训练超快，Facebook出品
https://github.com/facebookresearch/wav2letter

轻量语音识别解码框架
https://github.com/robin1001/xdecoder

Espresso：快速端到端神经网络语音识别工具集
https://github.com/freewym/espresso

PyTorch音频处理工具/数据集
https://github.com/audeering/audtorch

AI音源分离：Facebook AI的Demucs项目帮机器像人一样听音乐
https://github.com/facebookresearch/demucs

Youka：基于spleeter音源分离的卡拉OK生成工具
https://github.com/youkaclub/youka-desktop

基于卷积网络的基音检测
https://0xfe.blogspot.com/2020/02/pitch-detection-with-convolutional.html?m=1

Implementation of "FastSpeech: Fast, Robust and Controllable Text to Speech"
https://github.com/Deepest-Project/FastSpeech

'基于Kaldi的aidatatang_200zh的训练之葵花宝典' 
https://github.com/datatang-ailab/aidatatang_200zh/blob/master/README.zh.md

### 【轻量快速语音合成】’LightSpeech - A Light, Fast and Robust Speech Synthesis.' 
https://github.com/xcmyz/lightspeech

DeepSpectrum：基于预训练图像CNN的音频数据特征抽取工具包
https://github.com/DeepSpectrum/DeepSpectrum

Landmark音频指纹
https://github.com/dpwe/audfprint

基于Kaldi/Tensorflow的神经网络说话人识别/鉴别系统
https://github.com/mycrazycracy/tf-kaldi-speaker

【PyTorch语音识别框架】’patter - speech-to-text framework in PyTorch with initial support for the DeepSpeech2 architecture 
https://github.com/ryanleary/patter

(语音)说话人分割相关资源大列表
https://github.com/wq2012/awesome-diarization

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/SpeechResearch/speechresearch.github.io

(PyTorch)Seq2Seq普通话Transformer语音识别
https://github.com/ZhengkunTian/Speech-Tranformer-Pytorch

Deep neural network based speech enhancement toolkit
https://github.com/jtkim-kaist/Speech-enhancement

音乐音频标记预训练深度网络模型
https://github.com/jordipons/musiCNN

End-to-End Automatic Speech Recognition on PyTorch
https://github.com/gentaiscool/end2end-asr-pytorch

(Pytorch)音源分离语音信号提取
https://github.com/AppleHolic/source_separation

Code and models for evaluating a state-of-the-art lip reading network
https://github.com/afourast/deep_lip_reading

### 声音模仿秀：5秒钟实时克隆任意语音
https://github.com/CorentinJ/Real-Time-Voice-Cloning

Program to benchmark various speech recognition APIs
https://github.com/Franck-Dernoncourt/ASR_benchmark

基于Transformer的TTS语音合成模型
https://github.com/xcmyz/Transformer-TTS

DIY智能音箱(资源列表)
https://github.com/voice-engine/make-a-smart-speaker/blob/master/zh.md

用深度学习实时克隆别人的声音
https://towardsdatascience.com/you-can-now-speak-using-someone-elses-voice-with-deep-learning-8be24368fa2b

用卷积网络从立体声音乐中分离乐器
https://towardsdatascience.com/audio-ai-isolating-instruments-from-stereo-music-using-convolutional-neural-networks-584ababf69de

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

面向下一代交互设备的开源语音交互操作系统
https://github.com/yodaos-project/yodaos

笑声检测器
https://github.com/ideo/LaughDetection

'ASRT_SpeechRecognition - A Deep-Learning-Based Chinese Speech Recognition System 基于深度学习的中文语音识别系统' by nl8590687
https://github.com/nl8590687/ASRT_SpeechRecognition

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

A Pytorch Implementation of "Neural Speech Synthesis with Transformer Network"
https://github.com/soobinseo/Transformer-TTS

This is research-code for Synthesizing Obama: Learning Lip Sync from Audio.
https://github.com/supasorn/synthesizing_obama_network_training

Voice Operated Character Animation https://voca.is.tue.mpg.de/en
https://github.com/TimoBolkart/voca

Deezer 的(Tensorflow)音源分离库，可用命令行直接提取音乐中的人声、钢琴、鼓声等
https://github.com/deezer/spleeter

【开源语音分离/增强库】
https://github.com/speechLabBcCuny/onssen

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG

Transforming Spectrum and Prosody for Emotional Voice Conversion with Non-Parallel Training Data
https://github.com/KunZhou9646/Nonparallel-emotional-VC

This is a PyTorch re-implementation of Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition.
https://github.com/foamliu/Speech-Transformer

【Athena：开源端到端语音识别引擎】
https://github.com/athena-team/athena

PREDICTING EXPRESSIVE SPEAKING STYLE FROM TEXT IN END-TO-END SPEECH SYNTHESIS
https://github.com/Yangyangii/TPGST-Tacotron

PyTorch implementation of LF-MMI for End-to-end ASR
https://github.com/YiwenShaoStephen/pychain

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/RayeRen/unsuper_tts_asr

 Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.
 https://github.com/CSTR-Edinburgh/ophelia

Efficient neural speech synthesis
https://github.com/MlWoo/LPCNet

Code for Vision-Infused Deep Audio Inpainting (ICCV 2019)
https://github.com/Hangz-nju-cuhk/Vision-Infused-Audio-Inpainter-VIAI

deep learning based speech enhancement using keras or pytorch
https://github.com/yongxuUSTC/sednn

Multi-voice singing voice synthesis
https://github.com/MTG/WGANSing

【用涂鸦“唱歌”：将图像合成为声音】
https://github.com/jeonghopark/SketchSynth-Simple

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG


【面向语音识别的中文/英文发音辞典】’
https://github.com/speech-io/BigCiDian

### 【Kaldi/TensorFlow实现的神经网络说话人验证系统】
https://github.com/someonefighting/tf-kaldi-speaker-master

### Facebook开源低延迟在线语音识别框架wav2letter
https://github.com/facebookresearch/wav2letter/wiki/Inference-Framework

【GridSound：在线数字音频编辑器】
https://github.com/GridSound/daw

【Asteroid：基于PyTorch的音源分离工具集】
https://github.com/mpariente/ASSteroid

【MelGAN 超快音频合成】
https://github.com/descriptinc/melgan-neurips

用深度学习生成钢琴音乐
https://github.com/haryoa/note_music_generator

音频分析/音乐检索相关数据集大列表
https://www.audiocontentanalysis.org/data-sets/

### 【用TensorRT在GPU上部署实时文本-语音合成应用】
https://devblogs.nvidia.com/how-to-deploy-real-time-text-to-speech-applications-on-gpus-using-tensorrt/

用WaveNet让语音受损用户重拾原声(少样本自适应自然语音合成)
https://deepmind.com/blog/article/Using-WaveNet-technology-to-reunite-speech-impaired-users-with-their-original-voices

(C++)音频文件波形图生成
https://github.com/bbc/audiowaveform

【时域卷积DeepFake变音检测】
https://github.com/dessa-public/fake-voice-detection

Athena：(Tensorflow)端到端自动语音识别引擎开源实现
https://github.com/didi/athena

SV2TTS 
https://github.com/CorentinJ/Real-Time-Voice-Cloning

### 【GPU上的特定领域自动语音识别模型】《How to Build Domain Specific Automatic Speech Recognition Models on GPUs》
https://devblogs.nvidia.com/how-to-build-domain-specific-automatic-speech-recognition-models-on-gpus/

【(音频)数字信号处理入门(Notebooks)】
https://github.com/earthspecies/from_zero_to_DSP

### 【at16k：Python语音识别库】’at16k - Trained models for automatic speech recognition (ASR). A library to quickly build applications that require speech to text conversion.'
https://github.com/at16k/at16k

一维卷积网络音频处理
https://github.com/KinWaiCheuk/nnAudio

CRF数据高效端到端语音识别工具集
https://github.com/thu-spmi/CAT

【音乐波形域音源分离】’Music Source Separation in the Waveform Domain - source separation in the waveform domain for music' 
https://github.com/facebookresearch/demucs

【Python实时音频频谱分析器】’Realtime_PyAudio_FFT - Realtime audio analysis in Python, using PyAudio and Numpy to extract and visualize FFT features from streaming audio.' 
https://github.com/tr1pzz/Realtime_PyAudio_FFT

Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis
https://github.com/NVIDIA/flowtron 

【文本语音合成(TTS)文献集】
https://github.com/erogol/TTS-papers

【CPU高性能实时文本语音合成系统】
https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/

【TensorFlow 2 实现的文本语音合成】
https://github.com/as-ideas/TransformerTTS

【语音增强/语音分离/音源分离相关资源大列表】
https://github.com/Wenzhe-Liu/awesome-speech-enhancement

【AudioMass：全功能网页版音频/波形编辑工具
https://github.com/pkalogiros/AudioMass

【CTC端到端语音识别&语料库】’CTC-based Automatic Speech Recogniton - CTC end -to-end ASR for timit and 863 corpus.' 
https://github.com/Diamondfan/CTC_pytorch

【TensorflowTTS：Tensorflow 2实现的最先进实时语音合成】
https://github.com/dathudeptrai/TensorflowTTS

【audio：面向语音行为检测、二值化、说话人识别、自动语音识别、情感识别等任务的音频标注工具】
https://github.com/midas-research/audino

【深度学习语音端点检测】
https://github.com/filippogiruzzi/voice_activity_detection

【用Kaldi快速训练语音识别系统】
https://github.com/JRMeyer/easy-kaldi

从一首歌的mp3中分离得到人声、谱子、各种乐器等，转化成符号表示
https://github.com/deezer/spleeter

'aukit - 语音处理工具箱，包含语音降噪、音频格式转换、特征频谱生成等模块'
https://github.com/KuangDD/aukit

【Keras示例：说话人识别】《Speaker Recognition》
https://keras.io/examples/audio/speaker_recognition_using_cnn/

基于RNN-Transducer的在线语音识别系统
https://github.com/theblackcat102/Online-Speech-Recognition

### 'TacotronV2 + WaveRNN - tacotronV2 + wavernn 实现中文语音合成(Tensorflow + pytorch)'
https://github.com/lturing/tacotronv2_wavernn_chinese

【miniaudio：C语言单文件音频回放/采集库】
https://github.com/dr-soft/miniaudio https://github.com/irmen/pyminiaudio

【TiramisuASR：用Tensorflow 2实现的语音识别引擎】
https://github.com/usimarit/TiramisuASR

A PyTorch implementation of dual-path RNNs (DPRNNs) based speech separation described in "Dual-path RNN: efficient long sequence modeling for time-domain single-channel speech separation".
https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation

Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural Speaker Embeddings
https://github.com/nii-yamagishilab/multi-speaker-tacotron

Code repo for ICME 2020 paper "Style-Conditioned Music Generation". VAE model that allows style-conditioned music generation.
https://github.com/daQuincy/DeepMusicvStyle

streaming attention networks for end-to-end automatic speech recognition
https://github.com/HaoranMiao/streaming-attention

[InterSpeech 2020] "AutoSpeech: Neural Architecture Search for Speaker Recognition" 
https://github.com/TAMU-VITA/AutoSpeech

Pytorch implementation of sparse_image_warp and an example of GoogleBrain's SpecAugment is given: A Simple Data Augmentation Method for Automatic Speech Recognition
https://github.com/bobchennan/sparse_image_warp_pytorch

A Generative Flow for Text-to-Speech via Monotonic Alignment Search
https://github.com/jaywalnut310/glow-tts

DeCoAR (self-supervised contextual representations for speech recognition)
https://github.com/awslabs/speech-representations

A pytorch implementation of the EATS: End-to-End Adversarial Text-to-Speech
https://github.com/yanggeng1995/EATS

Companion repository for the paper "A Comparison of Metric Learning Loss Functions for End-to-End Speaker Verification"
https://github.com/juanmc2005/SpeakerEmbeddingLossComparison

Melody extraction using joint detection and classification network
https://github.com/keums/melodyExtraction_JDC

Implementation of the AlignTTS
https://github.com/Deepest-Project/AlignTTS

An implementation of Microsoft's "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"
https://github.com/ming024/FastSpeech2

It's an naive implementation of Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech.
https://github.com/AppleHolic/multiband_melgan

PyTorch Implementation of FastSpeech 2 : Fast and High-Quality End-to-End Text to Speech
https://github.com/rishikksh20/FastSpeech2

GELP: GAN-Excited Linear Prediction
https://github.com/ljuvela/GELP

### CASR-DEMO(中文自动语音识别演示系统） - 基于Flask Web的中文自动语音识别演示系统,包含语音识别、语音合成、声纹识别之说话人识别
https://github.com/lihanghang/CASR-DEMO

Unofficial PyTorch implementation of Multi-Band MelGAN paper
https://github.com/rishikksh20/melgan

### 中文语音识别 - Chinese speech recognition
https://github.com/chenmingxiang110/Chinese-automatic-speech-recognition

### MASR 中文语音识别：端到端深度神经网络中文普通话语音识别项目
https://github.com/nobody132/masr

Plover：开源跨平台速记引擎，每分钟可录入200+单词
http://www.openstenoproject.org/plover/

【“Python机器学习声源分离”源码】
https://github.com/masahitotogami/python_source_separation

【可移植的C语言声学指纹库】
https://github.com/JorenSix/Olaf

SpeedySpeech：师生网络高质量实时语音合成系统
https://github.com/janvainer/speedyspeech

音频/语音预训练模型集
https://github.com/balavenkatesh3322/audio-pretrained-model

Piano transcription：钢琴曲MIDI文件转写工具
https://arxiv.org/abs/2010.01815 https://github.com/bytedance/piano_transcription

CorentinJ/Real-Time-Voice-Cloning 
https://github.com/KuangDD/zhrtvc

工业级语音识别文献集(Streaming ASR / Non-autoregressive ASR / WFST based ASR ...)
https://github.com/xingchensong/speech-recognition-papers

pyttsx3：Python离线语音合成库
https://github.com/nateshmbhat/pyttsx3

TensorflowASR：Tensorflow2实现的最先进语音识别
https://github.com/Z-yq/TensorflowASR

Cornell鸟鸣识别比赛第二名方案
https://github.com/vlomme/Birdcall-Identification-competition

micmon：从原始音频流分割创建音频数据集并训练声音检测模型的Python库
https://github.com/BlackLight/micmon

### LibreASR：开箱即用的流语音识别系统(基于PyTorch&fastai )
https://github.com/iceychris/LibreASR

Voicenet：语音和音频的综合Python处理库
https://github.com/Robofied/Voicenet

musicpy：音乐编程语言，用简洁的语法通过乐理逻辑写出优美音乐
https://github.com/Rainbow-Dreamer/musicpy

SOVA ASR：基于Wav2Letter架构的快速语音识别API
https://github.com/sovaai/sova-asr

### ZhTTS：CPU上的开源端到端实时中文语音合成系统
https://github.com/Jackiexiao/zhtts

SeeWav: 音频波形可视化包
https://github.com/adefossez/seewav

神经网络语音分离必读文献列表
https://github.com/JusperLee/Speech-Separation-Paper-Tutorial

PIKA: 基于Pytorch和(Py)Kaldi的轻量语音处理工具包
https://github.com/tencent-ailab/pika

### ESP-Skainet：智能语音助手，支持唤醒词识别和命令词识别
https://github.com/espressif/esp-skainet

### TensorFlow Lite (TFLite)的TTS模型集
https://github.com/tulasiram58827/TTS_TFLite

Elpis (Accelerated Transcription)：开发中的语音识别模型创建工具
https://github.com/CoEDL/elpis

MusicNet：带标注的古典音乐数据集(330+)，标注了每个音符的精确时间，演奏每个音符的乐器，以及这些音符在乐曲韵律结构中的位置
https://homes.cs.washington.edu/~thickstn/musicnet.html

AI音乐生成
https://alxmamaev.medium.com/generating-music-with-ai-or-transformers-go-brrrr-3a3ac5a04126

Real Time Speech Enhancement in the Waveform Domain (Interspeech 2020)We provide a PyTorch implementation of the paper Real Time Speech Enhancement in the Waveform Domain.
https://github.com/facebookresearch/denoiser

Implementation of MelNet in PyTorch to generate high-fidelity audio samples
https://github.com/jgarciapueyo/MelNet-SpeechGeneration

PPSpeech: Phrase based Parallel End-to-End TTS System
https://github.com/rishikksh20/PPSpeech

Implementation of Phase-aware speech enhancement with deep complex U-Net
https://github.com/mhlevgen/DCUNetTorchSound

Tensorflow 2.0 implementation of the paper: A Fully Convolutional Neural Network for Speech Enhancement
https://github.com/daitan-innovation/cnn-audio-denoiser

### Voice Conversion by CycleGAN (语音克隆/语音转换): CycleGAN-VC2
https://github.com/jackaduma/CycleGAN-VC2

HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
https://github.com/jik876/hifi-gan

Real-Time High-Fidelity Speech Synthesis without GPU
https://github.com/BogiHsu/WG-WaveNet

Official PyTorch implementation of Speaker Conditional WaveRNN
https://github.com/dipjyoti92/SC-WaveRNN

Pytorch implementation of "Efficienttts: an efficient and high-quality text-to-speech architecture"
https://github.com/liusongxiang/efficient_tts

HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis
https://github.com/rishikksh20/HiFi-GAN

An unofficial implementation of the paper "One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization".
https://github.com/cyhuang-tw/AdaIN-VC

TFGAN: Time and Frequency Domain Based Generative Adversarial Network for High-fidelity Speech Synthesis
https://github.com/rishikksh20/TFGAN

Efficient neural networks for analog audio effect modeling
https://github.com/csteinmetz1/micro-tcn

End-to-End Multi-Channel Transformer for Speech Recognition
https://arxiv.org/abs/2102.03951

Hugging Face的Transformers v4.3.0最新发布，hub模型库增加Facebook的Wav2Vec2自动语音识别模型
https://huggingface.co/facebook/wav2vec2-base-960h

LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search
https://arxiv.org/abs/2102.04040

End-to-end Audio-visual Speech Recognition with Conformers
https://arxiv.org/abs/2102.06657

### TTS_TFLite
https://github.com/tulasiram58827/TTS_TFLite

Memory-efficient Speech Recognition on Smart Devices
https://arxiv.org/abs/2102.11531

自监督学习语音识别，wav2vec 2.0框架封装版
https://github.com/mailong25/self-supervised-speech-recognition

音频自动描述相关资源列表
https://github.com/audio-captioning/audio-captioning-resources

### PyTorch implementation of "Conformer: Convolution-augmented Transformer for Speech Recognition" (INTERSPEECH 2020)
https://github.com/sooftware/conformer

OpenASR：基于Pytorch的端到端语音识别系统 
https://github.com/by2101/OpenASR

实时音频频谱生成(网页版)
https://borismus.github.io/spectrogram/

【WavEncoder：PyTorch后端的原始音频编码库】
https://github.com/shangeth/wavencoder

【Picovoice：用于大规模语音产品构建的端到端平台】
github.com/Picovoice/picovoice 

audlib：以深度学习为重点的Python语音信号处理库
https://github.com/raymondxyy/pyaudlib

Auto-Editor：命令行视频/音频自动编辑工具，自动切除静默部分
https://github.com/WyattBlue/auto-editor

The SpeechBrain Toolkit：PyTorch开源一体化语音工具包，可用来轻松开发最先进的语音系统，包括语音识别、讲话者识别、语音增强、多麦克风信号处理等
github.com/speechbrain/speechbrain

STT：用于训练和部署语音到文本模型的开源深度学习工具包
github.com/coqui-ai/STT

GigaSpeech：用于语音识别的大型现代数据集
github.com/SpeechColab/GigaSpeech

Desed dataset：家庭环境声音事件检测数据集与工具
github.com/turpaultn/DESED

### 'MASR中文语音识别(pytorch版) - 中文语音识别系列，读者可以借助它快速训练属于自己的中文语音识别模型，或直接使用预训练模型测试效果。
github.com/binzhouchn/masr 

端到端语音处理工具集
github.com/espnet/espnet ​​​ ​​​​

Spleeter语声分离Demo
github.com/deezer/spleeter

基于Tacotron 2 & Waveglow的多说话人情感文本语音合成(TTS)
github.com/ide8/tacotron2

《AutoVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss》(2019)
github.com/cyhuang-tw/AutoVC

教程(Colab)：从头开始语音识别
github.com/speechbrain/speechbrain/ ​​​​

Vosk-Browser：运行在浏览器里的语音识别库(基于WebAssembly)
github.com/ccoreilly/vosk-browser  ccoreilly.github.io/vosk-browser/

The SpeechBrain Toolkit：PyTorch开源一体化语音工具包，可用来轻松开发最先进的语音系统，包括语音识别、讲话者识别、语音增强、多麦克风信号处理等
speechbrain.github.io/

Speech Algorithms：语音算法集
github.com/Ryuk17/SpeechAlgorithms

torchsynth：面向音频机器学习研究的指出GPU的超快模块音频合成器，在GPU上合成音频的速度比实时(714mhz)快16200倍
github.com/torchsynth/torchsynth

MevonAI：语音情感识别
github.com/SuyashMore/MevonAI-Speech-Emotion-Recognition

### TensorVox：C++写的桌面神经网络语音合成应用
github.com/ZDisket/TensorVox

Music Demixing Challenge - Starter Kit：音乐音源分离挑战入门工具包
github.com/AIcrowd/music-demixing-challenge-starter-kit

LEAF：轻量嵌入式音频框架，用于音频合成和处理的C语言库
github.com/spiricom/LEAF

Word2Wave：基于WaveGAN和COALA的文本音频生成框架
github.com/ilaria-manco/word2wave 

基于深度学习的音-视语音增强和分离相关资源集
github.com/danmic/av-se

LAS_Mandarin_PyTorch：端到端的中文语音识别
github.com/jackaduma/LAS_Mandarin_PyTorch

基于PaddlePaddle实现的中文语音识别
github.com/yeyupiaoling/PaddlePaddle-DeepSpeech

PyTorch实现的DNN音源分离
github.com/tky823/DNN-based_source_separation

可在线演示(Colab)的企业级预训练多语言语音识别(STT)模型
https://pytorch.org/hub/snakers4_silero-models_stt/

openspeech：用PyTorch-Lightning和Hydra实现的的端到端语音识别开源工具包
github.com/sooftware/openspeech

Audio Augmentations：PyTorch音频增强库
github.com/Spijkervet/torchaudio-augmentations

FRILL：用TensorFlow-Lite实现设备端语音表示
https://arxiv.org/abs/2011.04609 https://ai.googleblog.com/2021/06/frill-on-device-speech-representations.html

DeepPhonemizer：基于Transformer模型的字音转换库，可用于高精度和高效率的文本语音转换生产系统
github.com/as-ideas/DeepPhonemizer

### 《HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis》
github.com/rishikksh20/multiband-hifigan

《VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech》(2021) 
github.com/jaywalnut310/vits

基于wav2vec2的自动语音识别
github.com/oliverguhr/wav2vec2-live

CoreAudioML：音频效果处理机器学习库
github.com/Alec-Wright/CoreAudioML

SoundPy：面向研究的语音/声音Python开发包
github.com/a-n-rose/Python-Sound-Tool

kaldifeat：PyTorch的Kaldi兼容特征抽取，支持CUDA & autograd
github.com/csukuangfj/kaldifeat

ttskit - 语音合成工具箱，Text To Speech Toolkit，多种音色可供选择的语音合成工具。
github.com/KuangDD/ttskit 

Chinese mandarin text to speech (MTTS)  中文 (普通话) 语音 合成 , by fastspeech 2 , implemented in pytorch, using waveglow as vocoder, with biaobei and aishell3 datasets #TODO
github.com/ranchlai/mandarin-tts

Common Voice Dataset：开源、多语言语音数据集
github.com/common-voice/cv-dataset

语音合成技术百花齐放，一篇综述带你全面梳理
https://weibo.com/ttarticle/p/show?id=2309404668701587932163

### Larynx：基于gruut & onnx的端到端文本语音合成系统
github.com/rhasspy/larynx

### Realtime-Voice-Clone-Chinese - AI拟声: 克隆您的声音并生成任意语音内容 
github.com/babysor/Realtime-Voice-Clone-Chinese

Speech Emotion Recognition：用 LSTM、CNN、SVM、MLP 进行语音情感识别，Keras 实现
github.com/Renovamen/Speech-Emotion-Recognition

ParallelTTS：快速语音合成模型，适用于英语、普通话/中文、日语、韩语、俄语和藏语（当前已测试）
github.com/atomicoo/ParallelTTS

Neural HMMs are all you need (for high-quality attention-free TTS)
https://arxiv.org/abs/2108.13320

praudio：面向深度学习音频应用的音频预处理框架
github.com/musikalkemist/praudio

为言语障碍人士合成自然语音的PnG NAT 模型
https://ai.googleblog.com/2021/08/recreating-natural-voices-for-people.html

大规模多样无序语音数据集的个性化语音识别模型
https://ai.googleblog.com/2021/09/personalized-asr-models-from-large-and.html

功能齐全的语音工具包：SpeechBrain，提供语音识别（支持普通话）、语音增强、语音处理、多麦克风信号处理、模块化定制等功能。
此外，该工具还提供了颇为齐全的教程文档，以便帮助开发者更好的入门语音识别技术。
github.com/speechbrain/speechbrain/ ​​​​

Music Demixing Challenge 2021音源分离比赛第四名方案
github.com/yoyololicon/music-demixing-challenge-ismir-2021-entry

Keras实例：CTC自动语音识别
https://keras.io/examples/audio/ctc_asr/

mdx-tutorial：音源分离开源工具教程
github.com/kuielab/mdx-tutorial

### wenet-kws：面向产品的端到端唤醒关键词检测工具包
github.com/wenet-e2e/wenet-kws

Wav2Vec2 STT Python：基于Wav2Vec2.0的语音识别库
github.com/daanzu/wav2vec2_stt_python

### PPASR流式与非流式语音识别 - 基于PaddlePaddle2实现的端到端中文语音识别框架
github.com/yeyupiaoling/PPASR

music2video：基于Wav2CLIP和VQGAN-CLIP根据音乐自动生成视频
github.com/joeljang/music2video

compound-word-transformer-tensorflow - Tensorflow 实现的AI作曲’
compound-word-transformer-tensorflow

MockingBird - AI拟声: 5秒内克隆您的声音并生成任意语音内容 
github.com/babysor/MockingBird

Wenet STT Python：基于WeNet的Python语音识别库
github.com/daanzu/wenet_stt_python 

### Spchcat：面向Linux/树莓派的语音识别工具，用于将音频转录为文本
github.com/petewarden/spchcat

Open Audio Search：开源音频搜索引擎(基于语音识别)
github.com/openaudiosearch/openaudiosearch 

语音识别资源集锦
https://wiki.nikitavoloboev.xyz/nlp/speech-recognition

HuggingSound：基于HuggingFace工具包的语音相关任务工具包
github.com/jonatasgrosman/huggingsound 

Muskit: 聚焦于端到端歌唱合成基准测试的开源音乐处理工具包，用PyTorch作为深度学习引擎，并遵循 ESPnet 和 Kaldi 风格的数据处理，为各种音乐处理实验提供完整设置
github.com/SJTMusicTeam/Muskits 

基于很少样本的神经乐器克隆
https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6

PaddleSpeech：基于飞桨PaddlePaddle的语音方向的开源模型库，用于语音和音频中的各种关键任务的开发，包含大量基于深度学习前沿和有影响力的模型
github.com/PaddlePaddle/PaddleSpeech

WeNet：面向工业落地应用的语音识别工具包，提供了从语音识别模型的训练到部署的一条龙服务
github.com/wenet-e2e/wenet 

IMS-Toucan：支持最新模型的语音合成工具包
github.com/DigitalPhonetics/IMS-Toucan

NeuralSpeech：微软亚研院的研究项目，专注于基于神经网络的语音处理，包括自动语音识别(ASR)、文本到语音转换(TTS)等
github.com/microsoft/NeuralSpeech

Tensorflow 2实现的最先进实时语音合成
github.com/TensorSpeech/TensorflowTTS ​​​​

Awesome Keyword Spotting：语音关键字检测(唤醒词检测)论文列表
github.com/zycv/awesome-keyword-spotting 

ocotillo - A fast, accurate and super simple speech recognition model - Performant and accurate speech recognition built on Pytorch
github.com/neonbjb/ocotillo 

libspecbleach：C语言音频降噪库
github.com/lucianodato/libspecbleach

NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality
提出了完全端到端文本波形生成系统NaturalSpeech，首次在LJSpeech数据集上实现了人类水平的质量。
https://arxiv.org/abs/2205.04421

sherpa：支持流式和非流式识别的Python语音识别服务框架
github.com/k2-fsa/sherpa 

audio-preview：VS Code的wav音频文件预览与播放扩展
github.com/sukumo28/vscode-audio-preview

【WeNet：面向工业落地应用的语音识别工具包，提供了从语音识别模型的训练到部署的一条龙服务】’WeNet - Production First and Production Ready End-to-End Speech Recognition Toolkit' by WeNet Open Source Community GitHub: github.com/wenet-e2e/wenet paper:《WeNet: Production First and Production Ready End-to-End Speech Recognition Toolkit》

【WeTTS：产品级端到端文本语音合成工具包】’WeTTS - Production First and Production Ready End-to-End Text-to-Speech Toolkit' by WeNet Open Source Community GitHub: github.com/wenet-e2e/wetts

【音频编码教程资料】’Audio Coding Video Tutorials and Python Notebooks - Audio Coding Notebooks and Tutorials' by Guitars.AI GitHub: github.com/GuitarsAI/AudioCodingTutorials

'wenet_trt8 - 用TRT8部署开源语音识别工具包WeNet，为语音识别模型在TRT8上部署提供参考方案’ by huismiling GitHub: github.com/huismiling/wenet_trt8

'FastASR - 基于PaddleSpeech所使用的conformer模型，使用C++的高效实现模型推理，在树莓派4B等ARM平台运行也可流畅运行' by chenkui164 GitHub: github.com/chenkui164/FastASR

【Open Text to Speech Server：开源多语言文本语音合成服务器】’Open Text to Speech Server - Open Text to Speech Server' by Michael Hansen GitHub: github.com/synesthesiam/opentts
