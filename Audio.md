CNN音频分割(音乐/人声/性别)工具集
https://github.com/ina-foss/inaSpeechSegmenter

最强CNN语音识别算法开源了：词错率5%，训练超快，Facebook出品
https://github.com/facebookresearch/wav2letter

轻量语音识别解码框架
https://github.com/robin1001/xdecoder

Espresso：快速端到端神经网络语音识别工具集
https://github.com/freewym/espresso

PyTorch音频处理工具/数据集
https://github.com/audeering/audtorch

AI音源分离：Facebook AI的Demucs项目帮机器像人一样听音乐
https://github.com/facebookresearch/demucs

Youka：基于spleeter音源分离的卡拉OK生成工具
https://github.com/youkaclub/youka-desktop

基于卷积网络的基音检测
https://0xfe.blogspot.com/2020/02/pitch-detection-with-convolutional.html?m=1

Implementation of "FastSpeech: Fast, Robust and Controllable Text to Speech"
https://github.com/Deepest-Project/FastSpeech

'基于Kaldi的aidatatang_200zh的训练之葵花宝典' 
https://github.com/datatang-ailab/aidatatang_200zh/blob/master/README.zh.md

### 【轻量快速语音合成】’LightSpeech - A Light, Fast and Robust Speech Synthesis.' 
https://github.com/xcmyz/lightspeech

DeepSpectrum：基于预训练图像CNN的音频数据特征抽取工具包
https://github.com/DeepSpectrum/DeepSpectrum

Landmark音频指纹
https://github.com/dpwe/audfprint

基于Kaldi/Tensorflow的神经网络说话人识别/鉴别系统
https://github.com/mycrazycracy/tf-kaldi-speaker

【PyTorch语音识别框架】’patter - speech-to-text framework in PyTorch with initial support for the DeepSpeech2 architecture 
https://github.com/ryanleary/patter

(语音)说话人分割相关资源大列表
https://github.com/wq2012/awesome-diarization

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/SpeechResearch/speechresearch.github.io

(PyTorch)Seq2Seq普通话Transformer语音识别
https://github.com/ZhengkunTian/Speech-Tranformer-Pytorch

Deep neural network based speech enhancement toolkit
https://github.com/jtkim-kaist/Speech-enhancement

音乐音频标记预训练深度网络模型
https://github.com/jordipons/musiCNN

End-to-End Automatic Speech Recognition on PyTorch
https://github.com/gentaiscool/end2end-asr-pytorch

(Pytorch)音源分离语音信号提取
https://github.com/AppleHolic/source_separation

Code and models for evaluating a state-of-the-art lip reading network
https://github.com/afourast/deep_lip_reading

### 声音模仿秀：5秒钟实时克隆任意语音
https://github.com/CorentinJ/Real-Time-Voice-Cloning

Program to benchmark various speech recognition APIs
https://github.com/Franck-Dernoncourt/ASR_benchmark

基于Transformer的TTS语音合成模型
https://github.com/xcmyz/Transformer-TTS

DIY智能音箱(资源列表)
https://github.com/voice-engine/make-a-smart-speaker/blob/master/zh.md

用深度学习实时克隆别人的声音
https://towardsdatascience.com/you-can-now-speak-using-someone-elses-voice-with-deep-learning-8be24368fa2b

用卷积网络从立体声音乐中分离乐器
https://towardsdatascience.com/audio-ai-isolating-instruments-from-stereo-music-using-convolutional-neural-networks-584ababf69de

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

面向下一代交互设备的开源语音交互操作系统
https://github.com/yodaos-project/yodaos

笑声检测器
https://github.com/ideo/LaughDetection

'ASRT_SpeechRecognition - A Deep-Learning-Based Chinese Speech Recognition System 基于深度学习的中文语音识别系统' by nl8590687
https://github.com/nl8590687/ASRT_SpeechRecognition

用卷积神经网络从立体声音乐中分离人声
https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785

A Pytorch Implementation of "Neural Speech Synthesis with Transformer Network"
https://github.com/soobinseo/Transformer-TTS

This is research-code for Synthesizing Obama: Learning Lip Sync from Audio.
https://github.com/supasorn/synthesizing_obama_network_training

Voice Operated Character Animation https://voca.is.tue.mpg.de/en
https://github.com/TimoBolkart/voca

Deezer 的(Tensorflow)音源分离库，可用命令行直接提取音乐中的人声、钢琴、鼓声等
https://github.com/deezer/spleeter

【开源语音分离/增强库】
https://github.com/speechLabBcCuny/onssen

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG

Transforming Spectrum and Prosody for Emotional Voice Conversion with Non-Parallel Training Data
https://github.com/KunZhou9646/Nonparallel-emotional-VC

This is a PyTorch re-implementation of Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition.
https://github.com/foamliu/Speech-Transformer

【Athena：开源端到端语音识别引擎】
https://github.com/athena-team/athena

PREDICTING EXPRESSIVE SPEAKING STYLE FROM TEXT IN END-TO-END SPEECH SYNTHESIS
https://github.com/Yangyangii/TPGST-Tacotron

PyTorch implementation of LF-MMI for End-to-end ASR
https://github.com/YiwenShaoStephen/pychain

Audio samples from ICML2019 "Almost Unsupervised Text to Speech and Automatic Speech Recognition"
https://github.com/RayeRen/unsuper_tts_asr

 Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.
 https://github.com/CSTR-Edinburgh/ophelia

Efficient neural speech synthesis
https://github.com/MlWoo/LPCNet

Code for Vision-Infused Deep Audio Inpainting (ICCV 2019)
https://github.com/Hangz-nju-cuhk/Vision-Infused-Audio-Inpainter-VIAI

deep learning based speech enhancement using keras or pytorch
https://github.com/yongxuUSTC/sednn

Multi-voice singing voice synthesis
https://github.com/MTG/WGANSing

【用涂鸦“唱歌”：将图像合成为声音】
https://github.com/jeonghopark/SketchSynth-Simple

Feature extractor for DL speech processing.
https://github.com/bepierre/SpeechVGG


【面向语音识别的中文/英文发音辞典】’
https://github.com/speech-io/BigCiDian

### 【Kaldi/TensorFlow实现的神经网络说话人验证系统】
https://github.com/someonefighting/tf-kaldi-speaker-master

### Facebook开源低延迟在线语音识别框架wav2letter
https://github.com/facebookresearch/wav2letter/wiki/Inference-Framework

【GridSound：在线数字音频编辑器】
https://github.com/GridSound/daw

【Asteroid：基于PyTorch的音源分离工具集】
https://github.com/mpariente/ASSteroid

【MelGAN 超快音频合成】
https://github.com/descriptinc/melgan-neurips

用深度学习生成钢琴音乐
https://github.com/haryoa/note_music_generator

音频分析/音乐检索相关数据集大列表
https://www.audiocontentanalysis.org/data-sets/

### 【用TensorRT在GPU上部署实时文本-语音合成应用】
https://devblogs.nvidia.com/how-to-deploy-real-time-text-to-speech-applications-on-gpus-using-tensorrt/

用WaveNet让语音受损用户重拾原声(少样本自适应自然语音合成)
https://deepmind.com/blog/article/Using-WaveNet-technology-to-reunite-speech-impaired-users-with-their-original-voices

(C++)音频文件波形图生成
https://github.com/bbc/audiowaveform

【时域卷积DeepFake变音检测】
https://github.com/dessa-public/fake-voice-detection

Athena：(Tensorflow)端到端自动语音识别引擎开源实现
https://github.com/didi/athena

SV2TTS 
https://github.com/CorentinJ/Real-Time-Voice-Cloning

### 【GPU上的特定领域自动语音识别模型】《How to Build Domain Specific Automatic Speech Recognition Models on GPUs》
https://devblogs.nvidia.com/how-to-build-domain-specific-automatic-speech-recognition-models-on-gpus/

【(音频)数字信号处理入门(Notebooks)】
https://github.com/earthspecies/from_zero_to_DSP

### 【at16k：Python语音识别库】’at16k - Trained models for automatic speech recognition (ASR). A library to quickly build applications that require speech to text conversion.'
https://github.com/at16k/at16k

一维卷积网络音频处理
https://github.com/KinWaiCheuk/nnAudio

CRF数据高效端到端语音识别工具集
https://github.com/thu-spmi/CAT

【音乐波形域音源分离】’Music Source Separation in the Waveform Domain - source separation in the waveform domain for music' 
https://github.com/facebookresearch/demucs

【Python实时音频频谱分析器】’Realtime_PyAudio_FFT - Realtime audio analysis in Python, using PyAudio and Numpy to extract and visualize FFT features from streaming audio.' 
https://github.com/tr1pzz/Realtime_PyAudio_FFT

Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis
https://github.com/NVIDIA/flowtron 

【文本语音合成(TTS)文献集】
https://github.com/erogol/TTS-papers

【CPU高性能实时文本语音合成系统】
https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/

【TensorFlow 2 实现的文本语音合成】
https://github.com/as-ideas/TransformerTTS

【语音增强/语音分离/音源分离相关资源大列表】
https://github.com/Wenzhe-Liu/awesome-speech-enhancement

【AudioMass：全功能网页版音频/波形编辑工具
https://github.com/pkalogiros/AudioMass

【CTC端到端语音识别&语料库】’CTC-based Automatic Speech Recogniton - CTC end -to-end ASR for timit and 863 corpus.' 
https://github.com/Diamondfan/CTC_pytorch

【TensorflowTTS：Tensorflow 2实现的最先进实时语音合成】
https://github.com/dathudeptrai/TensorflowTTS

【audio：面向语音行为检测、二值化、说话人识别、自动语音识别、情感识别等任务的音频标注工具】
https://github.com/midas-research/audino

【深度学习语音端点检测】
https://github.com/filippogiruzzi/voice_activity_detection

【用Kaldi快速训练语音识别系统】
https://github.com/JRMeyer/easy-kaldi

从一首歌的mp3中分离得到人声、谱子、各种乐器等，转化成符号表示
https://github.com/deezer/spleeter

'aukit - 语音处理工具箱，包含语音降噪、音频格式转换、特征频谱生成等模块'
https://github.com/KuangDD/aukit

【Keras示例：说话人识别】《Speaker Recognition》
https://keras.io/examples/audio/speaker_recognition_using_cnn/

基于RNN-Transducer的在线语音识别系统
https://github.com/theblackcat102/Online-Speech-Recognition

### 'TacotronV2 + WaveRNN - tacotronV2 + wavernn 实现中文语音合成(Tensorflow + pytorch)'
https://github.com/lturing/tacotronv2_wavernn_chinese

【miniaudio：C语言单文件音频回放/采集库】
https://github.com/dr-soft/miniaudio https://github.com/irmen/pyminiaudio

【TiramisuASR：用Tensorflow 2实现的语音识别引擎】
https://github.com/usimarit/TiramisuASR

A PyTorch implementation of dual-path RNNs (DPRNNs) based speech separation described in "Dual-path RNN: efficient long sequence modeling for time-domain single-channel speech separation".
https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation

Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural Speaker Embeddings
https://github.com/nii-yamagishilab/multi-speaker-tacotron

Code repo for ICME 2020 paper "Style-Conditioned Music Generation". VAE model that allows style-conditioned music generation.
https://github.com/daQuincy/DeepMusicvStyle

streaming attention networks for end-to-end automatic speech recognition
https://github.com/HaoranMiao/streaming-attention

[InterSpeech 2020] "AutoSpeech: Neural Architecture Search for Speaker Recognition" 
https://github.com/TAMU-VITA/AutoSpeech

Pytorch implementation of sparse_image_warp and an example of GoogleBrain's SpecAugment is given: A Simple Data Augmentation Method for Automatic Speech Recognition
https://github.com/bobchennan/sparse_image_warp_pytorch

A Generative Flow for Text-to-Speech via Monotonic Alignment Search
https://github.com/jaywalnut310/glow-tts

DeCoAR (self-supervised contextual representations for speech recognition)
https://github.com/awslabs/speech-representations

A pytorch implementation of the EATS: End-to-End Adversarial Text-to-Speech
https://github.com/yanggeng1995/EATS

Companion repository for the paper "A Comparison of Metric Learning Loss Functions for End-to-End Speaker Verification"
https://github.com/juanmc2005/SpeakerEmbeddingLossComparison

Melody extraction using joint detection and classification network
https://github.com/keums/melodyExtraction_JDC

Implementation of the AlignTTS
https://github.com/Deepest-Project/AlignTTS

An implementation of Microsoft's "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"
https://github.com/ming024/FastSpeech2

It's an naive implementation of Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech.
https://github.com/AppleHolic/multiband_melgan

PyTorch Implementation of FastSpeech 2 : Fast and High-Quality End-to-End Text to Speech
https://github.com/rishikksh20/FastSpeech2

GELP: GAN-Excited Linear Prediction
https://github.com/ljuvela/GELP

### CASR-DEMO(中文自动语音识别演示系统） - 基于Flask Web的中文自动语音识别演示系统,包含语音识别、语音合成、声纹识别之说话人识别
https://github.com/lihanghang/CASR-DEMO

Unofficial PyTorch implementation of Multi-Band MelGAN paper
https://github.com/rishikksh20/melgan

### 中文语音识别 - Chinese speech recognition
https://github.com/chenmingxiang110/Chinese-automatic-speech-recognition