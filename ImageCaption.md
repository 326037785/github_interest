Recognition to Cognition Networks https://visualcommonsense.com
https://github.com/rowanz/r2c

CVPR 2018 - Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present
https://github.com/chenxinpeng/ARNet

Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training
https://github.com/bei21/img2poem

Dataset and starting code for visual entailment dataset https://arxiv.org/abs/1811.10582
https://github.com/necla-ml/SNLI-VE

Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
https://github.com/shikorab/SceneGraph

Tensorflow implementation of "A Structured Self-Attentive Sentence Embedding"
https://github.com/flrngel/Self-Attentive-tensorflow

This repository contains the reference code for the paper Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions (CVPR 2019).
https://github.com/aimagelab/show-control-and-tell 

Learning to Evaluate Image Captioning. CVPR 2018
https://github.com/richardaecn/cvpr18-caption-eval

Official Tensorflow Implementation of the paper "Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning" in CVPR 2018, with code, model and prediction results.
https://github.com/JaywongWang/DenseVideoCaptioning

A PyTorch implementation of Transformer in "Attention is All You Need" https://arxiv.org/abs/1706.03762
https://github.com/dreamgonfly/Transformer-pytorch

### Video Grounding and Captioning
https://github.com/facebookresearch/grounded-video-description