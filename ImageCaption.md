Recognition to Cognition Networks https://visualcommonsense.com
https://github.com/rowanz/r2c

CVPR 2018 - Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present
https://github.com/chenxinpeng/ARNet

Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training
https://github.com/bei21/img2poem

Dataset and starting code for visual entailment dataset https://arxiv.org/abs/1811.10582
https://github.com/necla-ml/SNLI-VE

Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction
https://github.com/shikorab/SceneGraph

### 【视觉/语言预训练模型最新进展】'Recent Advances in Vision and Language PreTrained Models (VL-PTMs)'
https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers

Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations
https://github.com/fenglinliu98/MIA

Tensorflow implementation of "A Structured Self-Attentive Sentence Embedding"
https://github.com/flrngel/Self-Attentive-tensorflow

This repository contains the reference code for the paper Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions (CVPR 2019).
https://github.com/aimagelab/show-control-and-tell 

The Code for ICME2019 Grand Challenge: Short Video Understanding (Single Model Ranks 6th)
https://github.com/guoday/ICME2019-CTR

【基于Transformer的图像自动描述PyTorch/Fairseq扩展】
https://github.com/krasserm/fairseq-image-captioning

Code for Neural Inverse Knitting: From Images to Manufacturing Instructions
https://github.com/xionluhnis/neural_inverse_knitting

Code for paper "Attention on Attention for Image Captioning". ICCV 2019 https://arxiv.org/abs/1908.06954
https://github.com/husthuaan/AoANet

Learning to Evaluate Image Captioning. CVPR 2018
https://github.com/richardaecn/cvpr18-caption-eval

Vision-Language Pre-training for Image Captioning and Question Answering
https://github.com/LuoweiZhou/VLP

Official Tensorflow Implementation of the paper "Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning" in CVPR 2018, with code, model and prediction results.
https://github.com/JaywongWang/DenseVideoCaptioning

A PyTorch implementation of Transformer in "Attention is All You Need" https://arxiv.org/abs/1706.03762
https://github.com/dreamgonfly/Transformer-pytorch

《ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data》
https://www.arxiv-vanity.com/papers/2001.07966/

【结合BERT的图片描述生成】’Image Captioning System - BERT + Image Captioning'
https://github.com/ajamjoom/Image-Captions

M^2: Meshed-Memory Transformer for Image Captioning
https://github.com/aimagelab/meshed-memory-transformer

### Video Grounding and Captioning
https://github.com/facebookresearch/grounded-video-description

Reformer：高效的Transformer
https://github.com/google/trax/tree/master/trax/models/reformer

ICCV研讨会的中英文视频描述大赛
http://vatex.org/main/index.html

Cooperative Vision-and-Dialog Navigation
https://github.com/mmurray/cvdn

Auto-Encoding Scene Graphs for Image Captioning, CVPR 2019
https://github.com/yangxuntu/SGAE

A PyTorch implementation of the Transformer model from "Attention Is All You Need".
https://github.com/phohenecker/pytorch-transformer

【MMF：基于PyTorch的视觉/语言研究模块化框架，可方便进行VQA、图像描述、视觉对话、仇恨检测和其他视觉/语言任务的研究】
https://github.com/facebookresearch/mmf

基于transformers的图像Instagram标题生成
https://github.com/antoninodimaggio/Hugging-Captions

Implementation of 'X-Linear Attention Networks for Image Captioning' [CVPR 2020]
https://github.com/JDAI-CV/image-captioning

Train Scene Graph Generation for Visual Genome and GQA in PyTorch >= 1.2 with improved zero and few-shot generalization. Paper: "Graph Density-Aware Losses for Novel Compositions in Scene Graph Generation"
https://github.com/bknyaz/sgg

Code and Resources for the Transformer Encoder Reasoning Network (TERN) - https://arxiv.org/abs/2004.09144
https://github.com/mesnico/TERN

Code for ACL 2020 paper "Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA."
https://github.com/hyounghk/VideoQADenseCapFrameGate-ACL2020

[ACL 2020] PyTorch code for MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning
https://github.com/jayleicn/recurrent-transformer

PyTorch code for: Learning to Generate Grounded Visual Captions without Localization Supervision
https://github.com/chihyaoma/cyclical-visual-captioning

Say As You Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs
https://github.com/cshizhe/asg2cap

Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning
https://github.com/cshizhe/hgr_v2t

The repository of ECCV 2020 paper `Active Visual Information Gathering for Vision-Language Navigation
https://github.com/HanqingWangAI/Active_VLN

Code for the CVPR 2020 oral paper: Weakly Supervised Visual Semantic Parsing
https://github.com/alirezazareian/vspnet https://arxiv.org/abs/2001.02359

Learning Visual Representations with Caption Annotations
https://arxiv.org/abs/2008.01392
